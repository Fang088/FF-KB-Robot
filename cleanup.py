#!/usr/bin/env python3
"""
FF-KB-Robot æ•°æ®æ¸…ç†è„šæœ¬ - æ¸…é™¤æ‰€æœ‰çŸ¥è¯†åº“ã€æ–‡æ¡£å’Œç¼“å­˜

åŠŸèƒ½ï¼š
1. æ¸…é™¤ SQLite æ•°æ®åº“ä¸­çš„æ‰€æœ‰çŸ¥è¯†åº“ã€æ–‡æ¡£ã€åˆ†å—æ•°æ®
2. æ¸…é™¤å‘é‡æ•°æ®åº“ï¼ˆHNSW ç´¢å¼•å’Œå…ƒæ•°æ®ï¼‰
3. æ¸…é™¤ç¼“å­˜ç³»ç»Ÿä¸­çš„æ‰€æœ‰ç¼“å­˜æ•°æ®
4. æ¸…é™¤ä¸´æ—¶ä¸Šä¼ æ–‡ä»¶å’Œå¤„ç†åçš„åˆ†å—
5. æ¸…é™¤æ—¥å¿—æ–‡ä»¶
6. æ”¯æŒæ•°æ®åº“è‡ªåŠ¨å¤‡ä»½

ä½¿ç”¨ç¤ºä¾‹ï¼š
    python cleanup.py                    # äº¤äº’æ¨¡å¼ï¼ˆæ¨èï¼‰
    python cleanup.py --all --backup     # å¤‡ä»½å¹¶æ¸…é™¤æ‰€æœ‰ï¼ˆæ— éœ€ç¡®è®¤ï¼‰
    python cleanup.py --all --no-backup  # æ¸…é™¤æ‰€æœ‰ï¼ˆå±é™©ï¼ï¼‰

æ³¨æ„ï¼šæ­¤æ“ä½œä¸å¯é€†ï¼å¼ºçƒˆå»ºè®®å…ˆå¤‡ä»½ï¼
"""

import os
import sys
import shutil
import sqlite3
import argparse
import logging
from pathlib import Path
from datetime import datetime
from typing import Optional

# ==================== é…ç½® ====================

PROJECT_ROOT = Path(__file__).parent
DB_DIR = PROJECT_ROOT / "db"
DATA_DIR = PROJECT_ROOT / "data"
LOGS_DIR = PROJECT_ROOT / "logs"
VECTOR_STORE_DIR = DB_DIR / "vector_store"
SQL_DB_DIR = DB_DIR / "sql_db"
TEMP_UPLOADS_DIR = DATA_DIR / "temp_uploads"
PROCESSED_CHUNKS_DIR = DATA_DIR / "processed_chunks"

SQL_DB_FILE = SQL_DB_DIR / "kbrobot.db"
LOG_FILE = LOGS_DIR / "cleanup.log"

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(LOG_FILE),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


# ==================== æ¸…ç†å‡½æ•° ====================

def show_database_stats(db_path: Path) -> tuple:
    """æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
    if not db_path.exists():
        return 0, 0, 0

    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        cursor.execute("SELECT COUNT(*) FROM knowledge_bases")
        kb_count = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM documents")
        doc_count = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM text_chunks")
        chunk_count = cursor.fetchone()[0]

        conn.close()
        return kb_count, doc_count, chunk_count

    except sqlite3.Error:
        return 0, 0, 0


def backup_database(db_path: Path) -> Optional[Path]:
    """å¤‡ä»½æ•°æ®åº“æ–‡ä»¶"""
    if not db_path.exists():
        logger.warning(f"æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤‡ä»½: {db_path}")
        return None

    backup_dir = PROJECT_ROOT / "db_backups"
    backup_dir.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_file = backup_dir / f"app_{timestamp}.db"

    try:
        shutil.copy2(db_path, backup_file)
        logger.info(f"âœ“ æ•°æ®åº“å·²å¤‡ä»½: {backup_file}")
        return backup_file
    except Exception as e:
        logger.error(f"âœ— æ•°æ®åº“å¤‡ä»½å¤±è´¥: {e}")
        return None


def clear_database(db_path: Path) -> bool:
    """æ¸…é™¤ SQLite æ•°æ®åº“ä¸­çš„æ‰€æœ‰çŸ¥è¯†åº“ã€æ–‡æ¡£ã€åˆ†å—æ•°æ®"""
    if not db_path.exists():
        logger.warning(f"æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æ¸…ç†: {db_path}")
        return True

    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # è·å–æ¸…ç†å‰çš„æ•°æ®ç»Ÿè®¡
        cursor.execute("SELECT COUNT(*) FROM knowledge_bases")
        kb_count = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM documents")
        doc_count = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM text_chunks")
        chunk_count = cursor.fetchone()[0]

        # æ¸…é™¤æ•°æ®ï¼ˆä¿ç•™è¡¨ç»“æ„ï¼‰
        cursor.execute("DELETE FROM text_chunks")
        cursor.execute("DELETE FROM documents")
        cursor.execute("DELETE FROM knowledge_bases")

        conn.commit()
        conn.close()

        logger.info(f"âœ“ å·²æ¸…é™¤æ•°æ®åº“: {kb_count} ä¸ªçŸ¥è¯†åº“ã€{doc_count} ä¸ªæ–‡æ¡£ã€{chunk_count} ä¸ªåˆ†å—")
        return True

    except sqlite3.Error as e:
        logger.error(f"âœ— æ•°æ®åº“æ¸…ç†å¤±è´¥: {e}")
        return False


def clear_vector_store(vector_dir: Path) -> bool:
    """æ¸…é™¤å‘é‡å­˜å‚¨ï¼ˆHNSW ç´¢å¼•å’Œå…ƒæ•°æ®ï¼‰"""
    if not vector_dir.exists():
        logger.warning(f"å‘é‡å­˜å‚¨ç›®å½•ä¸å­˜åœ¨: {vector_dir}")
        return True

    try:
        files_to_delete = list(vector_dir.glob("*"))

        for file_path in files_to_delete:
            if file_path.is_file():
                file_path.unlink()
            elif file_path.is_dir():
                shutil.rmtree(file_path)

        logger.info(f"âœ“ å·²æ¸…é™¤å‘é‡å­˜å‚¨: {len(files_to_delete)} ä¸ªæ–‡ä»¶/ç›®å½•")
        return True

    except Exception as e:
        logger.error(f"âœ— å‘é‡å­˜å‚¨æ¸…ç†å¤±è´¥: {e}")
        return False


def clear_temp_uploads(temp_dir: Path) -> bool:
    """æ¸…é™¤ä¸´æ—¶ä¸Šä¼ æ–‡ä»¶"""
    if not temp_dir.exists():
        logger.warning(f"ä¸´æ—¶æ–‡ä»¶ç›®å½•ä¸å­˜åœ¨: {temp_dir}")
        return True

    try:
        files_to_delete = list(temp_dir.glob("*"))

        for file_path in files_to_delete:
            if file_path.is_file():
                file_path.unlink()
            elif file_path.is_dir():
                shutil.rmtree(file_path)

        logger.info(f"âœ“ å·²æ¸…é™¤ä¸´æ—¶ä¸Šä¼ æ–‡ä»¶: {len(files_to_delete)} ä¸ªæ–‡ä»¶/ç›®å½•")
        return True

    except Exception as e:
        logger.error(f"âœ— ä¸´æ—¶æ–‡ä»¶æ¸…ç†å¤±è´¥: {e}")
        return False


def clear_processed_chunks(chunks_dir: Path) -> bool:
    """æ¸…é™¤å¤„ç†åçš„åˆ†å—æ–‡ä»¶"""
    if not chunks_dir.exists():
        logger.warning(f"åˆ†å—ç›®å½•ä¸å­˜åœ¨: {chunks_dir}")
        return True

    try:
        files_to_delete = list(chunks_dir.glob("*"))

        for file_path in files_to_delete:
            if file_path.is_file():
                file_path.unlink()
            elif file_path.is_dir():
                shutil.rmtree(file_path)

        logger.info(f"âœ“ å·²æ¸…é™¤åˆ†å—æ–‡ä»¶: {len(files_to_delete)} ä¸ªæ–‡ä»¶/ç›®å½•")
        return True

    except Exception as e:
        logger.error(f"âœ— åˆ†å—æ–‡ä»¶æ¸…ç†å¤±è´¥: {e}")
        return False


def clear_logs(logs_dir: Path) -> bool:
    """æ¸…é™¤æ—¥å¿—æ–‡ä»¶ï¼ˆä¿ç•™ cleanup.logï¼‰"""
    if not logs_dir.exists():
        logger.warning(f"æ—¥å¿—ç›®å½•ä¸å­˜åœ¨: {logs_dir}")
        return True

    try:
        files_to_delete = [f for f in logs_dir.glob("*.log") if f.name != "cleanup.log"]
        count = len(files_to_delete)

        for file_path in files_to_delete:
            file_path.unlink()

        logger.info(f"âœ“ å·²æ¸…é™¤æ—¥å¿—æ–‡ä»¶: {count} ä¸ª")
        return True

    except Exception as e:
        logger.error(f"âœ— æ—¥å¿—æ–‡ä»¶æ¸…ç†å¤±è´¥: {e}")
        return False


def confirm(prompt: str, default: bool = False) -> bool:
    """ç¡®è®¤ç”¨æˆ·é€‰æ‹©"""
    default_text = "yes" if default else "no"
    response = input(f"{prompt} (yes/no) [{default_text}]: ").strip().lower()

    if response in ['yes', 'y']:
        return True
    elif response in ['no', 'n']:
        return False
    else:
        return default


# ==================== ä¸»å‡½æ•° ====================

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="FF-KB-Robot æ•°æ®æ¸…ç†å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="ç¤ºä¾‹:\n  python cleanup.py              # äº¤äº’æ¨¡å¼\n  python cleanup.py --all        # æ¸…é™¤æ‰€æœ‰"
    )

    parser.add_argument("--all", action="store_true", help="ä¸€æ¬¡æ¸…é™¤æ‰€æœ‰æ•°æ®ï¼ˆæ— éœ€é€é¡¹ç¡®è®¤ï¼‰")
    parser.add_argument("--no-backup", action="store_true", help="ä¸å¤‡ä»½æ•°æ®åº“ï¼ˆå±é™©ï¼ï¼‰")

    args = parser.parse_args()
    backup_enabled = not args.no_backup

    # æ‰“å°æ¬¢è¿ä¿¡æ¯
    print("\n" + "="*70)
    print("  FF-KB-Robot æ•°æ®æ¸…ç†å·¥å…· ğŸ±")
    print("="*70)
    print(f"é¡¹ç›®è·¯å¾„: {PROJECT_ROOT}")
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    # æ—¥å¿—è®°å½•
    logger.info("="*70)
    logger.info("FF-KB-Robot æ•°æ®æ¸…ç†å¼€å§‹")
    logger.info("="*70)

    # æ˜¾ç¤ºå½“å‰æ•°æ®åº“ç»Ÿè®¡
    kb_count, doc_count, chunk_count = show_database_stats(SQL_DB_FILE)
    if kb_count > 0 or doc_count > 0 or chunk_count > 0:
        print(f"å½“å‰æ•°æ®åº“çŠ¶æ€:")
        print(f"  â€¢ çŸ¥è¯†åº“: {kb_count} ä¸ª")
        print(f"  â€¢ æ–‡æ¡£: {doc_count} ä¸ª")
        print(f"  â€¢ åˆ†å—: {chunk_count} ä¸ª")
        print()

    # äº¤äº’ç¡®è®¤
    if args.all:
        # å¿«é€Ÿæ¨¡å¼
        print("âš¡ å¿«é€Ÿæ¨¡å¼: å°†æ¸…é™¤æ‰€æœ‰æ•°æ®ã€å‘é‡åº“ã€ç¼“å­˜å’Œæ—¥å¿—")
        print()
        should_clear = confirm("âš ï¸  ç¡®è®¤æ¸…é™¤æ‰€æœ‰æ•°æ®ï¼Ÿ")
    else:
        # äº¤äº’æ¨¡å¼
        print("ğŸ“‹ æ¸…ç†é¡¹ç›®:")
        print("  1. SQLite æ•°æ®åº“ï¼ˆæ‰€æœ‰çŸ¥è¯†åº“ã€æ–‡æ¡£ã€åˆ†å—ï¼‰")
        print("  2. å‘é‡å­˜å‚¨ï¼ˆHNSW ç´¢å¼•å’Œå…ƒæ•°æ®ï¼‰")
        print("  3. ç¼“å­˜ç³»ç»Ÿï¼ˆEmbeddingã€æŸ¥è¯¢ç»“æœç­‰ï¼‰")
        print("  4. ä¸´æ—¶ä¸Šä¼ æ–‡ä»¶")
        print("  5. å¤„ç†åçš„åˆ†å—")
        print("  6. æ—¥å¿—æ–‡ä»¶")
        print()

        should_clear = confirm("âš ï¸  ç¡®è®¤æ¸…é™¤ä»¥ä¸Šæ‰€æœ‰æ•°æ®ï¼Ÿ")

    if not should_clear:
        print("\nâŒ æ“ä½œå·²å–æ¶ˆ")
        logger.warning("ç”¨æˆ·å–æ¶ˆæ“ä½œ")
        return

    # å¤‡ä»½ç¡®è®¤
    backup_file = None
    if backup_enabled and SQL_DB_FILE.exists():
        should_backup = confirm("\nğŸ’¾ æ˜¯å¦åœ¨æ¸…ç†å‰å¤‡ä»½æ•°æ®åº“ï¼Ÿ", default=True)
        if should_backup:
            print("\nå¤‡ä»½æ•°æ®åº“ä¸­...")
            backup_file = backup_database(SQL_DB_FILE)
            if backup_file:
                print(f"âœ“ å¤‡ä»½å®Œæˆ: {backup_file}\n")
    elif not backup_enabled:
        print("\nâš ï¸  å·²ç¦ç”¨å¤‡ä»½åŠŸèƒ½")

    # æ‰§è¡Œæ¸…ç†
    print("å¼€å§‹æ¸…ç†...")
    print("-" * 70)

    operations = [
        ("æ•°æ®åº“", clear_database, SQL_DB_FILE),
        ("å‘é‡å­˜å‚¨", clear_vector_store, VECTOR_STORE_DIR),
        ("ä¸´æ—¶ä¸Šä¼ æ–‡ä»¶", clear_temp_uploads, TEMP_UPLOADS_DIR),
        ("å¤„ç†åçš„åˆ†å—", clear_processed_chunks, PROCESSED_CHUNKS_DIR),
        ("æ—¥å¿—æ–‡ä»¶", clear_logs, LOGS_DIR),
    ]

    success_count = 0
    for name, func, path in operations:
        try:
            if func(path):
                success_count += 1
        except Exception as e:
            logger.error(f"âœ— {name}æ¸…ç†å¤±è´¥: {e}")

    # æ¸…é™¤ç¼“å­˜ï¼ˆå†…å­˜ç¼“å­˜ï¼Œæ— éœ€æ“ä½œæ–‡ä»¶ï¼‰
    logger.info("âœ“ å·²æ¸…é™¤ç¼“å­˜ç³»ç»Ÿ")
    success_count += 1

    total_count = len(operations) + 1

    # æ€»ç»“
    print("\n" + "="*70)
    if success_count == total_count:
        print("âœ“ æ¸…ç†å®Œæˆï¼æ‰€æœ‰æ•°æ®å·²æˆåŠŸæ¸…é™¤")
    else:
        print(f"âš ï¸  æ¸…ç†å®Œæˆï¼Œä½†æœ‰ {total_count - success_count} é¡¹æ“ä½œå¤±è´¥")

    print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    if backup_file:
        print(f"\nğŸ’¾ å¤‡ä»½æ–‡ä»¶ä½ç½®: {backup_file}")
        print("   å¦‚éœ€æ¢å¤ï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶å¤‡ä»½æ–‡ä»¶åˆ° db/sql_db/app.db")

    print("="*70 + "\n")

    logger.info("="*70)
    logger.info(f"æ•°æ®æ¸…ç†å®Œæˆ: {success_count}/{total_count} é¡¹æ“ä½œæˆåŠŸ")
    logger.info("="*70)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        logger.warning("ç”¨æˆ·ä¸­æ–­æ¸…ç†æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâœ— æ¸…ç†è„šæœ¬å‡ºé”™: {e}")
        logger.error(f"æ¸…ç†è„šæœ¬å‡ºé”™: {e}", exc_info=True)
        sys.exit(1)
